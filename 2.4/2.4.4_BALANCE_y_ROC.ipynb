{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["***\n","BASADO EN https://github.com/Lawrence-Krukrubo/Machine_Learning\n","***\n"],"metadata":{"id":"PLErrxjpURqS"}},{"cell_type":"markdown","source":["# Exploración de los datos"],"metadata":{"id":"ZQEqFznaiOZo"}},{"cell_type":"code","metadata":{"id":"iDhT4fAxgOzZ"},"source":["print(__doc__)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import itertools\n","from sklearn.metrics import roc_curve, auc\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4MzCNjgh2W0"},"source":["Importemos su conjunto de datos  y creemos un dataframe en Pandas"]},{"cell_type":"code","metadata":{"id":"CuVVGqibiAwq"},"source":["data_link = 'sample_data/diabetes.csv'\n","\n","diabetes_df = pd.read_csv(data_link)\n","\n","diabetes_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wy36kU00ijM8"},"source":["Verifiquemos la forma y si existen valores faltantes."]},{"cell_type":"code","metadata":{"id":"fD2ShA1Qin4x"},"source":["diabetes_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CrAm8bWLiqro"},"source":["diabetes_df.isna().any()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PlahZq0mYx_"},"source":["Veamos la distribución de cada columna, esto nos ayudaría a elegir el método de normalización de características más ideal.<br>\n","Primero, definamos un método que represente la distribución de cada característica."]},{"cell_type":"code","metadata":{"id":"wVySOHK8msHN"},"source":["def plot_features(data):\n","    plt.figure(figsize=(20, 10))\n","    sns.set(font_scale=1.2)\n","    sns.set_style('ticks') # change background to white background\n","    plt.suptitle('Visualizing The Features Distribution', y=0.95)\n","\n","    plt.subplot(241)\n","    color_list = ['gold','purple','brown']\n","    data.Age.plot(kind='hist', color='brown')\n","    plt.xlabel('Age')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(242)\n","    color_list = ['gold','purple','brown']\n","    data.Pregnancies.plot(kind='hist', color='brown')\n","    plt.xlabel('Pregnancies')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(243)\n","    color_list = ['gold','purple','brown']\n","    data.PlasmaGlucose.plot(kind='hist', color='brown')\n","    plt.xlabel('PlasmaGlucose')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(244)\n","    color_list = ['gold','purple','brown']\n","    data.DiastolicBloodPressure.plot(kind='hist', color='brown')\n","    plt.xlabel('DiastolicBP')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(245)\n","    color_list = ['gold','purple','brown']\n","    data.TricepsThickness.plot(kind='hist', color='brown')\n","    plt.xlabel('TricepsThickness')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(246)\n","    color_list = ['gold','purple','brown']\n","    data.SerumInsulin.plot(kind='hist', color='brown')\n","    plt.xlabel('SerumInsulin')\n","    plt.ylabel('Frequency')\n","\n","\n","    plt.subplot(247)\n","    color_list = ['gold','purple','brown']\n","    data.BMI.plot(kind='hist', color='brown')\n","    plt.xlabel('BMI')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(248)\n","    color_list = ['gold','purple','brown']\n","    data.DiabetesPedigree.plot(kind='hist', color='brown')\n","    plt.xlabel('DiabetesPedigree')\n","    plt.ylabel('Frequency')\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4PlJMg7JAsP"},"source":["plot_features(diabetes_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eWkfoi6FF7AG"},"source":["Podemos ver que características como Edad, DiabetesPedigree, SerumInsulin e IMC parecen estar sesgadas hacia la derecha.<br>\n","Esto se debe a una gran cantidad de valores más pequeños y a una distribución progresiva de menos valores grandes.<br>\n","Mejoremos la distribución usando el registro de los valores, en lugar de los valores reales en estas características.<br>\n","Esta es una parte del proceso de ingeniería de características en Machine Learning"]},{"cell_type":"code","metadata":{"id":"B1uy0emlF5kY"},"source":["for i in diabetes_df.columns:\n","    if i in ['Age', 'DiabetesPedigree', 'BMI', 'SerumInsulin']:\n","        print(i)\n","        diabetes_df[i] = diabetes_df[i].apply(np.log)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wgOV2tyLJjQ"},"source":["Veamos la distribución de nuevo."]},{"cell_type":"code","metadata":{"id":"t4bVNsQRJjEz"},"source":["plot_features(diabetes_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qYiYg3NkLN3c"},"source":["De los gráficos anteriores, podemos ver una mejora en la distribución de nuestras características.<br>\n","Esto nos ayudaría a lograr un mejor resultado cuando entrenamos el modelo."]},{"cell_type":"markdown","metadata":{"id":"7vXTDeo5mDGQ"},"source":["Bien, ahora veamos el conjunto de datos que contiene los nombres de los médicos que tratan a nuestros respectivos pacientes.\n","Lo cargamos en un dataframe."]},{"cell_type":"code","metadata":{"id":"K0J90XTBs0JW"},"source":["doctors_link = 'sample_data/doctors.csv'\n","\n","doctors_df = pd.read_csv(doctors_link, encoding='latin-1')\n","\n","doctors_df.head()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG01OWeTs_rr"},"source":["doctors_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SlFJ3NsoHX-"},"source":["doctors_df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jPIhFJE-pU7C"},"source":["Entonces podemos ver que los datos del Doctor son ligeramente más pequeños que el conjunto de datos de los pacientes.<br>\n","Esto puede deberse al hecho de que algunos médicos vieron a más de un paciente.<br>\n","\n","-------------------\n","Unamos a la izquierda los marcos de datos diabetes_df y doctors_df usando el ID del paciente como clave de unión.<br>\n","La unión a la izquierda aquí es importante para que mantengamos los datos de los pacientes que pueden no tener nombres de médicos también."]},{"cell_type":"code","metadata":{"id":"lw7IvlJCpNxu"},"source":["diabetes_doctor_df = pd.merge(diabetes_df, doctors_df, how='left', on='PatientID' )\n","\n","diabetes_doctor_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKUdBM_wtMlE"},"source":["Ahora podemos ver la columna de médicos adjunta y podemos decir qué médico trató a un paciente.<br>\n","Veamos la forma y también verifiquemos el número y las columnas con valores nulos"]},{"cell_type":"code","metadata":{"id":"DZoyhLr5tnCh"},"source":["diabetes_doctor_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVrVwD_nt0DE"},"source":["diabetes_doctor_df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ts9Qxqcft5Jd"},"source":["No hay valores faltantes, la razón podría ser que algunos médicos trataron a varios pacientes."]},{"cell_type":"markdown","metadata":{"id":"QZUqsBVhtiCp"},"source":["Verifiquemos la cantidad de médicos únicos en la lista de médicos"]},{"cell_type":"code","metadata":{"id":"lX_Pxqw2tHL8"},"source":["diabetes_doctor_df.Physician.nunique()\n","\n","# We can see that there are 109 doctors who treated these 15000 patients"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xscYfjYC0LsS"},"source":["Verifiquemos también la cantidad de pacientes únicos en el conjunto de datos"]},{"cell_type":"code","metadata":{"id":"k_5RIFmWz78a"},"source":["diabetes_doctor_df.PatientID.nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VtylrfUE0ZEB"},"source":["Ahora tiene sentido,<br>\n","Hay 14895 pacientes únicos y los registros médicos tienen entradas para exactamente 14895 pacientes.<br>\n","El hecho de que el conjunto de datos de los pacientes tenga 15000 entradas se debe simplemente a que algunos pacientes tenían varias entradas.<br>\n","Dado que fusionamos los médicos y los pacientes en la columna de ID de paciente, la fusión asigna correctamente a cada médico a los pacientes que trató, aunque solo tenemos 109 médicos únicos."]},{"cell_type":"code","metadata":{"id":"LQ3LCTeHujMP"},"source":["diabetes_doctor_df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DqesEjlvwu7o"},"source":["### Preparación de datos"]},{"cell_type":"markdown","metadata":{"id":"fcBhfmN8w6Bf"},"source":["Como suele ser el caso con el aprendizaje automático de cualquier tipo, se requiere cierta preparación de datos antes de poder\n","use los datos para entrenar un modelo.<br>\n","Normalizaremos las características para que las características que tienen valores grandes no dominen el entrenamiento.<br>\n","Al observar las formas de la distribución de cada característica, aquellas con una forma de campana de distribución más o menos normal se normalizarán mediante el método Zscore.<br>\n","Mientras que aquellos con valores grandes y bajos variables se normalizarán utilizando el método Min-Max."]},{"cell_type":"markdown","metadata":{"id":"LRNm0Ccq3YKH"},"source":["**1. Z-Score or Standard Score**_  \n","  \n","\n","$Xnew =$ $Xold - mean \\over STD(sigma)$"]},{"cell_type":"markdown","metadata":{"id":"bSw1UjuF3gEq"},"source":["_**2. Min-Max Method**_  \n","\n","\n","$Xnew =$ $Xold - Xmin \\over Xmax - Xmin$"]},{"cell_type":"markdown","metadata":{"id":"kokc-lzf4Lj2"},"source":["Ahora apliquemos estos métodos a las columnas seleccionadas usando el método de aplicación."]},{"cell_type":"code","metadata":{"id":"dH-o3IJ04bDf"},"source":["for i in diabetes_doctor_df.columns[:-2]:\n","    mean = diabetes_doctor_df[i].mean()\n","    std = diabetes_doctor_df[i].std()\n","    mini = diabetes_doctor_df[i].min()\n","    maxi = diabetes_doctor_df[i].max()\n","\n","    # if columns are not Age or Pregnancies, apply the Z_score norm method\n","    if i not in ['Age', 'Pregnancies']:\n","        diabetes_doctor_df[i] = diabetes_doctor_df[i].apply(lambda x: (x - mean) / std)\n","\n","    # Else if columns are either Age or Pregnancies, then apply the Min-Max norm method\n","    else:\n","        diabetes_doctor_df[i] = diabetes_doctor_df[i].apply(lambda x: (x - mini) / (maxi - mini))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYPtSab0OWPf"},"source":["diabetes_doctor_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"glrVj-wWQ9Wk"},"source":["Ahora que hemos preparado el conjunto de datos, lo usaremos para entrenar y evaluar una máquina clasificadora.\n","modelo de aprendizaje Por lo general, cuando se entrena un modelo de aprendizaje supervisado, en el que los datos de entrenamiento incluyen\n","valores de etiqueta conocidos, dividimos los datos en un conjunto de entrenamiento con el que entrenar el modelo y un conjunto de prueba\n","con el que validar las predicciones generadas por el modelo entrenado."]},{"cell_type":"markdown","metadata":{"id":"3SXwGGcBEJl8"},"source":["Antes de continuar, verifiquemos la cantidad de observaciones que tiene cada clase de diabéticos o no diabéticos<br>"]},{"cell_type":"code","metadata":{"id":"3TTEkwcmD48w"},"source":["diabetes_doctor_df.Diabetic.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nkD1PnqFMTz"},"source":["Visualizemos la distribución"]},{"cell_type":"code","metadata":{"id":"u-xqbIxEFKI_"},"source":["plt.figure(figsize=(6, 6))\n","\n","sns.countplot(x=diabetes_doctor_df[\"Diabetic\"])\n","plt.title('Count of Diabetics and Non-Diabetics')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6AJqd9wDTnjP"},"source":["Podemos ver que de las 15 000 observaciones en nuestro conjunto de datos, la clase No diabético tiene 10 000 entradas, mientras que la clase Diabético tiene solo 5000 entradas.<br>\n","Este es un conjunto de datos desequilibrado y el riesgo que implica es que nuestro modelo puede aprender las características de una clase más que la otra.<br>\n","Necesitamos encontrar una manera de equilibrar el conjunto de datos para una clasificación más imparcial y confiable."]},{"cell_type":"markdown","metadata":{"id":"8f6vQ7rDTjTx"},"source":["Antes de hacer la división, seleccionemos solo las columnas que importan anulando las columnas ID del paciente y Médico."]},{"cell_type":"code","metadata":{"id":"Sbh6IhSqQ8IH","outputId":"6c2b2695-64cd-48ae-b73a-2707358e1a10","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["feature_matrix = diabetes_doctor_df.iloc[:,1:-2]\n","feature_matrix.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Pregnancies  PlasmaGlucose  DiastolicBloodPressure  TricepsThickness  \\\n","0     0.000000       1.974335                0.523867          0.356286   \n","1     0.571429      -0.495806                1.299582          1.249406   \n","2     0.500000       0.223349               -1.445258          1.592914   \n","3     0.642857      -0.151863                0.404526         -0.262028   \n","4     0.071429      -0.714680               -0.729213         -0.124625   \n","\n","   SerumInsulin       BMI  DiabetesPedigree       Age  \n","0     -1.364665  1.165284          1.755479  0.000000  \n","1     -0.908607 -1.076800         -0.637939  0.070017  \n","2     -0.937283  1.018286         -1.455161  0.070017  \n","3      1.263156 -0.041044          1.821124  0.551595  \n","4     -0.937283  1.099549          0.824581  0.035804  "],"text/html":["\n","  <div id=\"df-916d6c6d-0b07-4776-9fc0-bccba591d6e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>PlasmaGlucose</th>\n","      <th>DiastolicBloodPressure</th>\n","      <th>TricepsThickness</th>\n","      <th>SerumInsulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigree</th>\n","      <th>Age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>1.974335</td>\n","      <td>0.523867</td>\n","      <td>0.356286</td>\n","      <td>-1.364665</td>\n","      <td>1.165284</td>\n","      <td>1.755479</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.571429</td>\n","      <td>-0.495806</td>\n","      <td>1.299582</td>\n","      <td>1.249406</td>\n","      <td>-0.908607</td>\n","      <td>-1.076800</td>\n","      <td>-0.637939</td>\n","      <td>0.070017</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.500000</td>\n","      <td>0.223349</td>\n","      <td>-1.445258</td>\n","      <td>1.592914</td>\n","      <td>-0.937283</td>\n","      <td>1.018286</td>\n","      <td>-1.455161</td>\n","      <td>0.070017</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.642857</td>\n","      <td>-0.151863</td>\n","      <td>0.404526</td>\n","      <td>-0.262028</td>\n","      <td>1.263156</td>\n","      <td>-0.041044</td>\n","      <td>1.821124</td>\n","      <td>0.551595</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.071429</td>\n","      <td>-0.714680</td>\n","      <td>-0.729213</td>\n","      <td>-0.124625</td>\n","      <td>-0.937283</td>\n","      <td>1.099549</td>\n","      <td>0.824581</td>\n","      <td>0.035804</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-916d6c6d-0b07-4776-9fc0-bccba591d6e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-916d6c6d-0b07-4776-9fc0-bccba591d6e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-916d6c6d-0b07-4776-9fc0-bccba591d6e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"kAOjoX3rluz6"},"source":["definamos también nuestra variable de etiqueta"]},{"cell_type":"code","metadata":{"id":"ghv9W1Spl6hn"},"source":["label = diabetes_doctor_df.Diabetic\n","\n","label.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbi9YdKRTzjO"},"source":["feature_matrix.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0C42ux8TUKDG"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(feature_matrix, label, test_size=0.3, random_state=1234)\n","\n","print('X_train shape is',X_train.shape)\n","print('X_test shape is',X_test.shape)\n","print('y_train shape is',y_train.shape)\n","print('y_test shape is',y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z1DZRrpgm-O1"},"source":["Creamos Decision Tree Classifier"]},{"cell_type":"code","metadata":{"id":"Wt-xORLlpYHv"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn import metrics\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import log_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoGU06nCqMGw"},"source":["Definimos una función para imprimir la Confusion-Matrix"]},{"cell_type":"code","metadata":{"id":"D_i2i663qSyn"},"source":["from sklearn.metrics import classification_report\n","\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definamos una función que grafique la curva ROC"],"metadata":{"id":"g0mwv2gmIinI"}},{"cell_type":"code","source":["def plot_roc_chart(model):\n","     # calculate the fpr and tpr for all thresholds of the classification\n","    probs = model.predict_proba(X_test)\n","    preds = probs[:,1]\n","    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n","    roc_auc = metrics.auc(fpr, tpr)\n","\n","    # method I: plt\n","    plt.figure(figsize=(8,6))\n","    plt.title('Receiver Operating Characteristic')\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()\n","    return probs"],"metadata":{"id":"L5R1ue8YIjb9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qSrj-S1Fqc-B"},"source":["Definamos una función que devuelva el mejor modelo clasificador de árbol de decisión y genere sus parámetros y un gráfico de la matriz de confusión."]},{"cell_type":"code","metadata":{"id":"bRlK5jEBJ4Ng"},"source":["# set max depth range limit for DTree model to iterate through from 1 to 100 to find best parameters\n","\n","\n","def best_decision_tree_classifier(X_train, X_test, y_train, y_test):\n","    max_depth = 100\n","    accuracy_dict={'max_depth':0, 'val_acc':0, 'f1_Score':0, 'log_loss':0}\n","\n","    for i in range(1, max_depth+1):\n","            # Let's instantiate a model\n","            decision_model = DecisionTreeClassifier(criterion='entropy', max_depth = i)\n","\n","            # Let's train the model\n","            decision_model.fit(X_train, y_train)\n","\n","            # Let's make prediction on the test data\n","            y_hat = decision_model.predict(X_test)\n","\n","            # Let's measure accuracy of predictions on test data\n","            val_accu = round(metrics.accuracy_score(y_test, y_hat),4)\n","\n","            # Let's Measure the F1 Score\n","            val_f1 = round(f1_score(y_test, y_hat, average='weighted'),4)\n","\n","            # Let's Measure Logloss\n","            logloss = round(log_loss(y_test, y_hat, normalize=True),4)\n","\n","            if accuracy_dict['val_acc'] < val_accu or accuracy_dict['f1_Score'] < val_f1:\n","                accuracy_dict['max_depth'] = i\n","                accuracy_dict['val_acc'] = val_accu\n","                accuracy_dict['f1_Score'] = val_f1\n","                accuracy_dict['log_loss'] = logloss\n","                decision_model = decision_model\n","\n","            # Compute confusion matrix\n","            Dtrees_cnf_matrix = confusion_matrix(y_test, y_hat, labels=[1,0])\n","            np.set_printoptions(precision=2)\n","\n","            TP = Dtrees_cnf_matrix[0,0]\n","            FP = Dtrees_cnf_matrix[0,1]\n","            FN = Dtrees_cnf_matrix[1,0]\n","            TN = Dtrees_cnf_matrix[1,1]\n","\n","            accuracy = (TP + TN) / (TP + TN + FP + FN)\n","            recall = TP / (TP + FN)\n","            precision = TP / (TP + FP)\n","\n","    # Plot non-normalized confusion matrix\n","    plt.figure(figsize=(10, 6))\n","    sns.set(font_scale=1.3)\n","    plot_confusion_matrix(Dtrees_cnf_matrix,\n","                          classes=['Default=1','Non-Default=0'],\n","                          normalize= False,\n","                          title='Confusion Matrix for Decision-Tree-Classifier')\n","    plt.show()\n","    print()\n","\n","    print('TP is:',TP,'FP is:',FP,'TN is:',TN,'FN is:',FN)\n","    print()\n","    print('Model Evaluation:')\n","    print(accuracy_dict)\n","    print()\n","    plot_roc_chart(decision_model)\n","    print()\n","    print('accuracy is:',round(accuracy,2))\n","    print('recall is:',round(recall,2))\n","    print('precision is:',round(precision,2))\n","    print()\n","\n","    return decision_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZzLQQN1hkrC"},"source":["decision_tree_classifier = best_decision_tree_classifier(X_train, X_test, y_train, y_test)\n","decision_tree_classifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D3gG2D7wqgw3"},"source":["## Consideraciones"]},{"cell_type":"markdown","metadata":{"id":"5e0gNw2ah8rz"},"source":["Tenga en cuenta lo siguiente sobre estas métricas:<br>\n","• La Matriz de Confusión muestra el número de Verdaderos Positivos y Verdaderos Negativos (casos\n","correctamente clasificados) y Falsos Negativos y Falsos Positivos (casos incorrectamente clasificados).<br>\n","\n","• Accuracy es la fracción de casos clasificados correctamente.<br>\n","• Recall, es la fracción de casos positivos clasificados correctamente del total de casos positivos en el conjunto de datos. <br>\n","• Precision es la fracción de casos positivos clasificados correctamente de todos los casos clasificados como positivos."]},{"cell_type":"markdown","source":["Equilibremos el conjunto de datos y entrenemos un nuevo modelo"],"metadata":{"id":"4xHmXPlnJYMI"}},{"cell_type":"markdown","source":["Necesitamos equilibrar el conjunto de datos porque en un conjunto de datos desequilibrado, la precisión no es una métrica confiable para el rendimiento real de un clasificador, ya que arrojará resultados engañosos (es decir, cuando el número de observaciones en diferentes clases varía mucho).< br>\n","Por ejemplo, 70% de no morosos y 30% de morosos, un clasificador particular podría clasificar todas o la mayoría de las observaciones como No morosos.<br>\n","Esto se debe a que el clasificador o modelo tiene una alta tasa de reconocimiento (sensibilidad) para la clase dominante.<br>\n","[Puntuación F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) también sería incluso menos fiable en un conjunto de datos desequilibrado."],"metadata":{"id":"Tq2YcmhVJgNb"}},{"cell_type":"markdown","source":["**SMOTE - Synthetic Minority Over-sampling Technique** [link](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html)"],"metadata":{"id":"l2CC_23UJuiS"}},{"cell_type":"markdown","source":["***\n","EJERCICIO: busque los mejores parámetros para la llamada a SMOTE\n","***"],"metadata":{"id":"Pc6ul6vJMW7v"}},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","#sm = SMOTE(COLOQUE SUS PARAMETROS AQUI)"],"metadata":{"id":"KCGllBm0JxS5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["over_sampled_features, over_sampled_label = sm.fit_resample(feature_matrix, label)"],"metadata":{"id":"HpU6mAb2J0Uf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Shape of resampled feature set is:',over_sampled_features.shape)\n","print('Shape of resampled target data is:',over_sampled_label.shape)"],"metadata":{"id":"us5NsRs6J3tC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Concatenemos las características y el objetivo de nuevo en un dataframe"],"metadata":{"id":"TNRB2eskJ-0N"}},{"cell_type":"code","source":["over_sampled_df = pd.DataFrame(over_sampled_features, columns=['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age'])\n","\n","over_sampled_df['Diabetic'] = over_sampled_label\n","\n","over_sampled_df.head()"],"metadata":{"id":"fRvl1GhXKFvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["over_sampled_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O84PzKEqKJ04","outputId":"f386eac2-c2ce-415a-d2fd-c5e7185e4224"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20000, 9)"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["Visualizamos la nueva distribución"],"metadata":{"id":"xqQqoJx8KMDt"}},{"cell_type":"markdown","source":["***\n","EJERCICIO : grafique la nueva distribucion de las clases\n","***"],"metadata":{"id":"6fwHOK4bM68l"}},{"cell_type":"code","source":["plt.figure(figsize=(6, 6))\n","\n","# COLOQUE SUS CODIGO AQUI...\n","#"],"metadata":{"id":"1QiToryzKRHe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Bien, lo anterior es un conjunto de datos bien equilibrado. pasemos a entrenar el modelo dividiendo primero el conjunto de datos"],"metadata":{"id":"1ayl1Me-K9S7"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(over_sampled_df.iloc[:,:-1], over_sampled_df.Diabetic, test_size=0.3, random_state=1234)\n","\n","print('X_train shape is',X_train.shape)\n","print('X_test shape is',X_test.shape)\n","print('y_train shape is',y_train.shape)\n","print('y_test shape is',y_test.shape)"],"metadata":{"id":"-WFNodLoK_8S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Llamemos a DecisionTreeFunction para construir, clasificar y evaluar la predicción de nuestro modelo."],"metadata":{"id":"mUfpSZ8KLGDQ"}},{"cell_type":"code","source":["decision_tree_classifier = best_decision_tree_classifier(X_train, X_test, y_train, y_test)\n","decision_tree_classifier"],"metadata":{"id":"Uwwlad7aLLjm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***\n","# CONCLUSIÓN\n","Podemos ver claramente un aumento en el rendimiento del modelo simplemente equilibrando el conjunto de datos.<br>\n","El modelo generaliza mejor y es más preciso y seguro en sus tareas de clasificación."],"metadata":{"id":"sel-j_7hLboa"}}]}